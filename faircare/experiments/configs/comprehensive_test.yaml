# faircare/experiments/configs/comprehensive_test.yaml
# FairCare-FL v2.0 Comprehensive Performance Test Configuration

base:
  model:
    model_type: "mlp"
    hidden_dims: [64, 32]
    output_dim: 1
    dropout: 0.2
    activation: "relu"
  
  data:
    dataset: "adult"
    sensitive_attribute: "sex"
    n_clients: 10
    partition: "dirichlet"
    alpha: 0.3
    train_ratio: 0.7
    val_ratio: 0.15
    test_ratio: 0.15
    batch_size: 32
    seed: 42
  
  training:
    algo: "faircare_fl"
    rounds: 50
    local_epochs: 2
    lr: 0.03
    weight_decay: 0.0001
    momentum: 0.0
    server_lr: 1.0
    eval_every: 1
    checkpoint_every: 10
    device: "cpu"
  
  fairness:
    version: "2.0.0"
    
    # Client-side CALT parameters
    prox_mu: 0.01
    lambda_irm: 0.4
    lambda_adv: 0.15
    use_mixup: true
    use_cia: true
    
    # Server-side PFA parameters
    mgda_normalize_grads: true
    mgda_solver: "qp"
    mgda_step_size: 1.0
    pcgrad_enabled: true
    cagrad_enabled: true
    cagrad_rho: 0.45
    
    # Fairness dual ascent
    fairness_duals_enabled: true
    epsilon_eo: 0.08
    epsilon_fpr: 0.08
    epsilon_sp: 0.06
    dual_lr: 0.05
    
    # Demographics-free bias discovery
    arl_enabled: true
    arl_eta: 1.5
    arl_width: 128
    arl_depth: 2
    arl_lr: 0.001
    
    # Fairness-aware client selection
    selector_enabled: true
    selector_mode: "lyapunov"
    selector_tau: 0.015
    selector_kappa: 0.6
    
    # Distillation (disabled for efficiency)
    distill_enabled: false
    distill_temperature: 2.0
    distill_steps: 100
    distill_batch_size: 64
    
    # Fairness metric weights
    alpha: 1.8
    beta: 1.0
    gamma: 1.0
    delta: 0.25
    w_eo: 1.5
    w_fpr: 0.8
    w_sp: 0.8
    
    # Temperature annealing
    tau: 1.5
    tau_init: 1.5
    tau_min: 0.15
    
    # Lambda fairness penalty
    lambda_fair: 0.15
    lambda_fair_init: 0.15
    lambda_fair_min: 0.01
    lambda_fair_max: 2.0
    
    # Server momentum
    server_momentum: 0.85
    
    # Bias detection thresholds
    bias_threshold_eo: 0.10
    bias_threshold_fpr: 0.10
    bias_threshold_sp: 0.07
    detector_patience: 2
    
    # Weight constraints
    epsilon: 0.015
    weight_clip: 6.0
    
    # Privacy (disabled for max performance)
    dp_enabled: false
    dp_clip: 1.0
    dp_noise_mult: 0.1
  
  algo:
    # Legacy component parameters
    qffl_q: 2.5
    q_eps: 0.0001
    afl_lambda: 0.12
    afl_smoothing: 0.01
    fedprox_mu: 0.01
  
  secure_agg:
    enabled: false
    protocol: "additive_masking"

param_grid:
  data.dataset: ["adult", "heart", "synth_health"]
  data.sensitive_attribute: ["sex"]
  training.algo: ["faircare_fl", "fedavg", "qffl", "afl"]
  fairness.alpha: [1.5, 1.8, 2.0]
  data.n_clients: [10, 15]
  data.alpha: [0.1, 0.3, 0.5]

seeds: [0, 1, 2, 3, 4]

# Minimal test configuration for quick validation
minimal_test:
  base:
    data:
      dataset: "adult"
      n_clients: 5
    training:
      rounds: 10
      local_epochs: 1
  param_grid:
    data.dataset: ["adult"]
    training.algo: ["faircare_fl", "fedavg"]
  seeds: [0, 1]
