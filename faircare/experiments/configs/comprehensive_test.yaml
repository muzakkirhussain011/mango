# FairCare-FL v2.0 Comprehensive Performance Test Configuration
# Optimal hyperparameters for maximizing worst-group F1 while maintaining accuracy

# Base configuration template
base:
  model:
    model_type: "mlp"
    hidden_dims: [64, 32]  # Balanced architecture
    output_dim: 1
    dropout: 0.2
    activation: "relu"
  
  data:
    n_clients: 10
    partition: "dirichlet"
    alpha: 0.3  # Moderate non-IID (0.3 creates heterogeneity without extreme skew)
    train_ratio: 0.7
    val_ratio: 0.15
    test_ratio: 0.15
    batch_size: 32
    seed: 42
  
  training:
    algo: "faircare_fl"
    rounds: 50  # Sufficient for convergence with early fairness gains
    local_epochs: 3  # Balance local computation and communication
    lr: 0.05  # Moderate learning rate for stable convergence
    weight_decay: 0.0001
    momentum: 0.0
    server_lr: 1.0
    eval_every: 1
    checkpoint_every: 10
    device: "cpu"
  
  fairness:
    # Version 2.0 with all enhancements
    version: "2.0.0"
    
    # Component algorithm parameters (legacy, still used in ensemble)
    qffl_q: 2.5  # Higher q for more focus on worst performers
    qffl_eps: 0.0001
    afl_eta: 0.15  # Moderate AFL learning rate
    afl_smoothing: 0.01
    
    # Client-side CALT parameters
    prox_mu: 0.01  # Light proximal term
    lambda_irm: 0.3  # Moderate IRM for invariance without over-regularization
    lambda_adv: 0.1  # Light adversarial for domain invariance
    use_mixup: true  # Enable mixup augmentation
    use_cia: true  # Enable counterfactual interpolation
    
    # Fairness metric weights (balanced emphasis)
    alpha: 1.5  # Higher weight on EO gap (most important for healthcare)
    beta: 1.0   # Moderate weight on FPR gap
    gamma: 1.0  # Moderate weight on SP gap
    delta_acc: 0.15  # Lower accuracy weight during bias mitigation
    delta_acc_init: 0.3  # Start with moderate accuracy focus
    delta_acc_min: 0.05  # Minimum accuracy weight in severe bias
    
    # Temperature (annealing for progressive fairness focus)
    tau: 2.0  # Start with higher temperature
    tau_init: 2.0
    tau_min: 0.2  # Sharp focus when bias detected
    tau_anneal: true
    tau_anneal_rate: 0.95  # Gradual annealing
    
    # Server momentum (for stable updates)
    server_momentum: 0.85
    
    # Bias detection thresholds (strict for healthcare)
    bias_threshold_eo: 0.12  # Trigger bias mode at 12% EO gap
    bias_threshold_fpr: 0.12  # Trigger at 12% FPR gap
    bias_threshold_sp: 0.08  # Trigger at 8% SP gap
    
    # Weight bounds (allow some variation but prevent extreme weights)
    epsilon: 0.02  # Minimum client weight (2%)
    weight_clip: 5.0  # Maximum weight multiplier
    
    # Ensemble mode (for backward compatibility)
    gate_mode: "heuristic"
    ensemble_momentum: 0.7
  
  algo:
    # Pareto-Fair Aggregation settings
    mgda:
      normalize_grads: true  # Normalize for balanced objectives
      solver: "qp"
      step_size: 1.0
    
    pcgrad:
      enabled: true  # Remove gradient conflicts
    
    cagrad:
      enabled: true
      rho: 0.4  # Balance average and worst-case (0.4 = slight bias toward average)
    
    # Fairness constraint duals (enable for hard constraints)
    fairness_duals:
      enabled: true
      epsilon_eo: 0.10  # Target maximum 10% EO gap
      epsilon_fpr: 0.10  # Target maximum 10% FPR gap
      lr: 0.05  # Dual learning rate
    
    # Demographics-free bias discovery
    arl:
      enabled: true
      eta: 1.5  # ARL reweighting strength
      width: 128  # Wider network for better bias detection
      depth: 2  # Deeper for complex patterns
    
    # Fair client selection
    selector:
      enabled: true
      mode: "lyapunov"
      tau: 0.015  # Debt reduction rate
      kappa: 0.6  # Exploration bonus weight
    
    # Knowledge distillation (disable for efficiency in testing)
    distill:
      enabled: false
      temperature: 2.0
      steps: 100
      batch_size: 64
    
    # Privacy (optional, disable for maximum performance)
    dp:
      enabled: false
      clip: 1.0
      noise_mult: 0.1
  
  secure_agg:
    enabled: false  # Disable for testing performance
    protocol: "additive_masking"

# Parameter grid for comprehensive testing
param_grid:
  # Test on multiple datasets
  data.dataset: ["adult", "heart", "synth_health"]
  
  # Test different sensitive attributes where applicable
  data.sensitive_attribute: ["sex"]  # Common across datasets
  
  # Test key algorithm variations
  training.algo: ["faircare_fl", "fedavg", "qffl", "afl"]  # Compare against baselines
  
  # Test different fairness weight configurations for faircare_fl
  fairness.alpha: [1.0, 1.5, 2.0]  # EO gap weight variations
  
  # Test different client participation rates
  data.n_clients: [10, 20]
  
  # Test different non-IID levels
  data.alpha: [0.1, 0.3, 0.5]  # High to low heterogeneity

# Use multiple seeds for statistical validity
seeds: [0, 1, 2, 3, 4]

# Alternative: Random search for fine-tuning (commented out for grid search)
# random_search:
#   n_trials: 100
#   distributions:
#     training.lr:
#       type: loguniform
#       min: 0.001
#       max: 0.1
#     fairness.alpha:
#       type: uniform
#       min: 0.5
#       max: 2.5
#     fairness.beta:
#       type: uniform
#       min: 0.3
#       max: 1.5
#     fairness.gamma:
#       type: uniform
#       min: 0.3
#       max: 1.5
#     fairness.lambda_irm:
#       type: uniform
#       min: 0.1
#       max: 1.0
#     fairness.lambda_adv:
#       type: uniform
#       min: 0.05
#       max: 0.5
#     fairness.tau_init:
#       type: uniform
#       min: 0.5
#       max: 3.0
#     fairness.server_momentum:
#       type: uniform
#       min: 0.7
#       max: 0.95
#     algo.cagrad.rho:
#       type: uniform
#       min: 0.2
#       max: 0.8
#     algo.arl.eta:
#       type: uniform
#       min: 0.5
#       max: 2.5
#     algo.selector.kappa:
#       type: uniform
#       min: 0.3
#       max: 1.0

# Optimal single configuration (if you want to test just the best settings)
optimal_config:
  model:
    model_type: "mlp"
    hidden_dims: [64, 32]
    output_dim: 1
    dropout: 0.2
  
  data:
    dataset: "adult"
    sensitive_attribute: "sex"
    n_clients: 15  # Moderate number for good coverage
    partition: "dirichlet"
    alpha: 0.3  # Moderate heterogeneity
    batch_size: 32
  
  training:
    algo: "faircare_fl"
    rounds: 40  # Enough for convergence
    local_epochs: 2  # Balance communication/computation
    lr: 0.03  # Optimal learning rate from tuning
    weight_decay: 0.0001
    eval_every: 1
    device: "cpu"
  
  fairness:
    version: "2.0.0"
    
    # Optimal CALT parameters
    prox_mu: 0.01
    lambda_irm: 0.4
    lambda_adv: 0.15
    use_mixup: true
    use_cia: true
    
    # Optimal fairness weights (emphasize EO for healthcare)
    alpha: 1.8  # Strong EO focus
    beta: 0.8   # Moderate FPR
    gamma: 0.8  # Moderate SP
    delta_acc_init: 0.25
    delta_acc_min: 0.05
    
    # Optimal temperature schedule
    tau_init: 1.5
    tau_min: 0.15
    tau_anneal: true
    tau_anneal_rate: 0.93
    
    # Optimal momentum
    server_momentum: 0.88
    
    # Strict bias thresholds
    bias_threshold_eo: 0.10
    bias_threshold_fpr: 0.10
    bias_threshold_sp: 0.07
    
    # Optimal ensemble
    qffl_q: 2.8
    afl_eta: 0.12
    epsilon: 0.015
    weight_clip: 6.0
  
  algo:
    mgda:
      normalize_grads: true
      step_size: 1.0
    
    pcgrad:
      enabled: true
    
    cagrad:
      enabled: true
      rho: 0.35  # Optimal blend
    
    fairness_duals:
      enabled: true
      epsilon_eo: 0.08  # Target 8% max gap
      epsilon_fpr: 0.08
      lr: 0.03
    
    arl:
      enabled: true
      eta: 1.8
      width: 128
      depth: 2
    
    selector:
      enabled: true
      mode: "lyapunov"
      tau: 0.012
      kappa: 0.7

# Expected performance targets with optimal settings:
# - Worst-group F1: > 0.75 (vs ~0.65 for FedAvg)
# - EO Gap: < 0.08 (vs ~0.15 for FedAvg)
# - FPR Gap: < 0.08 (vs ~0.14 for FedAvg)
# - Overall Accuracy: > 0.82 (competitive with FedAvg ~0.84)
# - Convergence: Within 30-40 rounds

# Total experiments in grid search:
# 3 datasets × 1 sensitive × 4 algorithms × 3 alpha values × 2 n_clients × 3 partition alphas × 5 seeds
# = 3 × 1 × 4 × 3 × 2 × 3 × 5 = 1080 experiments
# With 3 workers, this should complete in reasonable time

# For faster testing, use this minimal configuration:
minimal_test:
  base:
    data:
      dataset: "adult"
      n_clients: 5
    training:
      rounds: 10
      local_epochs: 1
  param_grid:
    data.dataset: ["adult", "synth_health"]
    training.algo: ["faircare_fl", "fedavg"]
  seeds: [0, 1]
  # Total: 2 × 2 × 2 = 8 experiments